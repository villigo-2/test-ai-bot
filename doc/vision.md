## Техническое видение (MVP, KISS)

### 1. Технологии (согласовано)
- Язык/рантайм: Python 3.11
- Telegram: `aiogram` 3.x (режим long polling на MVP)
- Источник данных: `pytrends` (Google Trends)
- Обработка данных: `pandas`, `numpy`
- Прогноз: наивный/линейный (через `numpy`) на короткий горизонт
- LLM: провайдер OpenRouter через OpenAI-совместимый клиент; модель указывается в конфигурации
- Гео/страны: внутренний маппинг названий стран → ISO-коды (например, «Казахстан» → `KZ`)
- Графики: `matplotlib` (генерация одного простого PNG-графика тренда)
- Конфигурация: переменные окружения из `.env` (`python-dotenv`)
- Логирование: стандартный модуль `logging`
- Деплой: Docker (один контейнер)
- Тестирование: `pytest`
- Управление зависимостями и окружением Python: `uv` (c `pyproject.toml`)
- Автоматизация сборки/запуска/деплоя: `Makefile`
- История диалога: in-memory структуры (`dict`/`list`) без БД; состояние не сохраняется между рестартами

### 2. Принцип разработки (согласовано)
- KISS и MVP-first: делаем минимально необходимую функциональность для проверки гипотезы.
- Итеративность: короткие инкременты, частые демонстрации.
- Тестируемость: только критические unit-тесты для чистых функций аналитики; остальное покрывается ручными сценариями.
- Прозрачность: один репозиторий, один сервис.
- Ограничение зависимостей: используем только утверждённый стек.
- Обработка ошибок: fail-safe ответы пользователю, чёткое логирование уровней `INFO/WARN/ERROR`.
- Конфигурация: `.env.example` в репозитории; реальные секреты только через переменные окружения.
- Код-стайл: простые правила; автоформаттеры (black/isort/ruff) можно добавить позже при необходимости.
- Документация: короткий `README` и этот документ — источник истины для MVP.

### 3. Структура проекта (согласовано)
- Корень:
  - `app/`
    - `main.py` — запуск бота (aiogram, long polling)
    - `config.py` — чтение переменных окружения
    - `bot/handlers.py` — обработчики команд и сообщений
    - `bot/state.py` — in-memory история/состояние: `dict[chat_id] -> list[message]`
    - `services/trends_client.py` — получение данных из Google Trends (`pytrends`)
    - `services/analysis.py` — базовые метрики и простой прогноз (наивный/линейный)
    - `services/plot.py` — генерация PNG-графика (`matplotlib`)
    - `services/llm_client.py` — вызовы LLM через OpenRouter (OpenAI-совместимый клиент)
    - `utils/country_map.py` — маппинг названий стран → ISO-коды
  - `tests/`
    - `test_analysis.py` — unit-тесты для метрик/прогноза (`pytest`)
  - `doc/` — документация
  - `.env.example` — шаблон конфигурации
  - `pyproject.toml` — зависимости/скрипты (`uv`)
  - `Makefile` — задачи: run, test, docker-build, docker-run
  - `Dockerfile` — сборка образа

- Минимальные публичные функции:
  - `trends_client.fetch_interest_over_time(query, geo, timeframe) -> pd.DataFrame`
  - `analysis.compute_metrics(df) -> dict`
  - `analysis.compute_simple_forecast(df, horizon) -> dict | pd.DataFrame`
  - `plot.render_trend_plot(df, forecast=None) -> bytes`
  - `llm_client.summarize(metrics, forecast, locale) -> str`

### 4. Архитектура проекта (минимальная, согласовано)
- Тип: монолитное приложение (один процесс/контейнер)
- Поток обработки: Telegram (Long polling) → `handlers` → `services`
- Интеграции:
  - Google Trends через `pytrends`
  - LLM через OpenRouter (OpenAI-совместимый клиент)
- Аналитика: простые метрики и прогноз в `analysis`
- Визуализация: один PNG-график в `plot`
- Состояние: in-memory история диалога на процесс, без внешнего хранилища
- Конфигурация: только ENV (`.env` для локальной разработки)
- Ошибки: обработка на границах (бот/внешние вызовы), дружелюбные ответы пользователю
- Кэширование: отсутствует на MVP
- Деплой: один Docker-образ, запуск через `make`

### 5. Модель данных (минимальная, согласовано)
- UserQuery (запрос пользователя):
  - `chat_id: int`
  - `text: str` — сырой текст запроса
  - `query: str` — нормализованный термин для поиска
  - `geo: str` — ISO-код страны (напр., `KZ`), по умолчанию `world`
  - `timeframe: str` — `7d|30d|12m|5y|all` или `YYYY-MM-DD:YYYY-MM-DD`
  - `created_at: datetime`
- TrendsSeries (временной ряд):
  - `points: list[tuple[datetime, int]]` — значения 0–100
  - `source: str` — `google_trends`
- Metrics (базовые метрики):
  - `mean: float`, `median: float`, `std: float`, `min: int`, `max: int`
  - `trend: str` — `up|down|flat`
  - `seasonality_hint: bool`
  - `peaks: list[datetime]` — (опционально ограничить N первыми)
- Forecast (простой прогноз):
  - `horizon: int` — число будущих точек
  - `points: list[tuple[datetime, float]]`
  - `method: str` — `naive|linear`
  - `note: str` — краткое пояснение ограничений точности
- Plot (график):
  - `image_bytes: bytes`
  - `mime: str` — `image/png`
- LLMExplanation (текстовое объяснение):
  - `text: str`
  - `model: str`
  - `lang: str`

- DialogState (in-memory): `dict[int, list[dict]]` — сообщения по `chat_id`,
  где элемент: `{ role: str, content: str, timestamp: datetime }`.

### 6. Работа с LLM (минимальная, согласовано)
- Провайдер: OpenRouter через OpenAI-совместимый SDK
- Модель: из ENV (`OPENROUTER_MODEL`), ключ: `OPENROUTER_API_KEY`
- Промптинг:
  - системный промпт зашит в код/конфиг, описывает формат и ограничения
  - вход: пользовательский ввод + `metrics`/`forecast` как факты; требуем краткий вывод без домыслов
- Контекст: текущий запрос + N последних сообщений из in-memory истории (усечение при превышении лимита)
- Формат ответа: обычный текст (без JSON на MVP)
- Лимиты: простое усечение истории и полей по длине ввода
- Таймаут/ретраи: 1 ретрай с небольшим бэкофом; таймаут запроса
- Локаль: RU/EN по языку пользователя
- Безопасность: ключи и модель только через ENV

### 7. Мониторинг LLM (минимальный, согласовано)
- Логи: фиксируем усечённые промпт/ответ (без PII) на уровне `INFO`; ошибки — на `ERROR` c кодом и временем
- Метрики: в логах считаем успешные/ошибочные ответы и латентность (мс)
- Сэмплирование: сохраняем 1 из N полных примеров в локальный файл для ручного аудита качества
- Алерты: отсутствуют на MVP (ручная проверка логов)
- Конфиденциальность: маскируем ключи/токены; не пишем персональные данные
- Fallback: при 2 подряд таймаутах/ошибках возвращаем краткий шаблонный ответ без LLM

### 8. Сценарии работы (минимальные, согласовано)
- `/start`: приветствие и краткая инструкция по формату запроса
- `/help`: примеры запросов и параметры (термин, страна, период)
- Текстовый запрос (например, «chatgpt; 12m; Казахстан»):
  - разбор параметров → `trends_client` → `analysis` → (опц.) `plot` → `llm_client` → ответ пользователю
- Изменение периода: пользователь присылает новый период и вызывает перерасчёт
- Сравнение терминов: не входит в MVP
- Ошибки ввода/интеграций: дружелюбное сообщение с просьбой скорректировать формат или повторить попытку

### 9. Деплой (минимальный, согласовано)
- Docker-образ: на базе `python:3.11-slim`
- Сборка/запуск: цели `make docker-build` и `make docker-run`
- Переменные окружения в контейнер: `BOT_TOKEN`, `OPENROUTER_API_KEY`, `OPENROUTER_MODEL`, при необходимости `OPENROUTER_BASE_URL`
- Сетевые требования: исходящий доступ к Telegram, OpenRouter, Google Trends
- Логи: вывод в stdout/stderr, сбор логов средой запуска
- Режим: один процесс, long polling
- Ресурсы: ~256–512 MB RAM достаточно для MVP
- Обновление: пересборка образа и перезапуск контейнера

### 10. Подход к конфигурированию (согласовано)
- `.env.example` хранится в репозитории; реальный `.env` — только локально/на сервере
- Чтение конфигов через `os.getenv`; в разработке можем использовать `python-dotenv` для автозагрузки `.env`
- Обязательные переменные валидируются на старте: `BOT_TOKEN`, `OPENROUTER_API_KEY`, `OPENROUTER_MODEL`
- Один профиль окружения; изменения поведения — только значениями ENV

### 11. Подход к логгированию (согласовано)
- Библиотека: стандартный `logging`
- Формат: `%(asctime)s %(levelname)s %(name)s %(message)s`
- Уровень по умолчанию: `INFO`; можно переключать через ENV `LOG_LEVEL`
- Включаем ключевые поля в сообщение (строкой/key=value): `chat_id`, `query`, `geo`, `timeframe`, `latency_ms`
- Ошибки внешних вызовов — `WARNING/ERROR` с исключением
- Вывод логов: только stdout/stderr (сбор средой запуска)


